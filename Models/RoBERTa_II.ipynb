{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fc8f7c-810d-44fe-9800-10a51d9d4eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('../Data/reviews_training_26000.csv')\n",
    "test = pd.read_csv('../Data/reviews_test_4000.csv')\n",
    "train = train[['review','sentiment']]\n",
    "test = test[['review','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bbef95-1258-4dfb-8eca-3d1fd4362488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords') # For Stop word removal\n",
    "import re\n",
    "import string \n",
    "def pre_process(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<br\\s*/?>', ' ', text)\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    #Space Removal\n",
    "    text = re.sub(\"^\\s+|\\s+$\", \"\", text)\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    #Removing Numbers\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    #Stop Word Removal \n",
    "    # tokens = nltk.word_tokenize(text)\n",
    "    # stop_words = nltk.corpus.stopwords.words(\"english\")\n",
    "    # tokens = [token for token in tokens if token not in stop_words]\n",
    "    #Stemming\n",
    "    # stemmer = nltk.stem.PorterStemmer()\n",
    "    # tokens = [stemmer.stem(token) for token in tokens]\n",
    "    # pre_processed_text = \" \".join(tokens)\n",
    "    # return(pre_processed_text)\n",
    "    return(text)\n",
    "    \n",
    "train['review'] = train['review'].apply(pre_process)\n",
    "test['review'] = test['review'].apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e166f19c-46f7-4cdc-81d2-1c6a46325235",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sentiment'] = train['sentiment'].map({'positive':1,'negative':0})\n",
    "test['sentiment'] = test['sentiment'].map({'positive':1,'negative':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a090ae-818a-4d6e-b661-ce0145924b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_train = [str(i) for i in train['review'].values]\n",
    "token_test = [str(i) for i in test['review'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bc24ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "# Roberta Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ca3f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = tokenizer.batch_encode_plus(token_train, truncation=True, padding=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad79e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_test = tokenizer.batch_encode_plus(token_test, truncation=True, padding=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f229d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_test['input_ids'].shape\n",
    "encoded_train['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3612f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "input_ids = torch.tensor(encoded_train['input_ids'])\n",
    "attention_masks = torch.tensor(encoded_train['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d113f6-0ce8-4d18-a1f9-0a5aa2ba600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaModel\n",
    "# Model Import\n",
    "model = RobertaModel.from_pretrained('roberta-base')\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, attention_mask=attention_masks)\n",
    "    logits = outputs[0]\n",
    "    probs = logits.softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91d36a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(token_val, padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382e6808-8a5f-492b-8931-ff6f7fdb49f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Use the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "model.to(device)\n",
    "\n",
    "# Model Predictions \n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs[0]\n",
    "    probs = logits.softmax(dim=1)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m103"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b338292ebfbba4efd1b0ccb231aef686b174b263dfac8f6c1f0631e73e21d78c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
