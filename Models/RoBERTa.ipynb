{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fc8f7c-810d-44fe-9800-10a51d9d4eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('../Data/reviews_training_26000.csv')\n",
    "test = pd.read_csv('../Data/reviews_test_4000.csv')\n",
    "train = df[['review','sentiment']]\n",
    "test = val[['review','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "05bbef95-1258-4dfb-8eca-3d1fd4362488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords') # For Stop word removal\n",
    "\n",
    "def pre_process(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<br\\s*/?>', ' ', text)\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    #Space Removal\n",
    "    text = re.sub(\"^\\s+|\\s+$\", \"\", text)\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    #Removing Numbers\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    #Stop Word Removal \n",
    "    # tokens = nltk.word_tokenize(text)\n",
    "    # stop_words = nltk.corpus.stopwords.words(\"english\")\n",
    "    # tokens = [token for token in tokens if token not in stop_words]\n",
    "    #Stemming\n",
    "    # stemmer = nltk.stem.PorterStemmer()\n",
    "    # tokens = [stemmer.stem(token) for token in tokens]\n",
    "    # pre_processed_text = \" \".join(tokens)\n",
    "    # return(pre_processed_text)\n",
    "    return(text)\n",
    "    \n",
    "train['review'] = train['review'].apply(pre_process)\n",
    "test['review'] = test['review'].apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e166f19c-46f7-4cdc-81d2-1c6a46325235",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sentiment'] = train['sentiment'].map({'positive':1,'negative':0})\n",
    "test['sentiment'] = test['sentiment'].map({'positive':1,'negative':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5d6fdf80-e146-4196-b1cf-c1b614a2e00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import nltk\n",
    "# # nltk.download('stopwords')\n",
    "# import string\n",
    "\n",
    "# def pre_process(text):\n",
    "#     text = text.lower()\n",
    "#     text = re.sub(\"<br><br/>\", \" \", text)\n",
    "#     text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "#     text = ''.join([i for i in text if not i.isdigit()])\n",
    "#     tokens = nltk.word_tokenize(text)\n",
    "#     stop_words = nltk.corpus.stopwords.words(\"english\")\n",
    "#     tokens = [token for token in tokens if token not in stop_words]\n",
    "#     stemmer = nltk.stem.PorterStemmer()\n",
    "#     tokens = [stemmer.stem(token) for token in tokens]\n",
    "#     pre_processed_text = \" \".join(tokens)\n",
    "#     return pre_processed_text\n",
    "\n",
    "# df['review'] = df['review'].apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b3a090ae-818a-4d6e-b661-ce0145924b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_val = [str(i) for i in df['review'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b5d113f6-0ce8-4d18-a1f9-0a5aa2ba600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# # Roberta Tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "# # Model Import\n",
    "# model = AutoModel.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "382e6808-8a5f-492b-8931-ff6f7fdb49f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# # Use the GPU if available\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "# model.to(device)\n",
    "\n",
    "# # Model Predictions \n",
    "# with torch.no_grad():\n",
    "#     outputs = model(**inputs)\n",
    "#     logits = outputs[0]\n",
    "#     probs = logits.softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e9547e-4a6f-4ce6-82d4-01086128a675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c8006f-2f31-41ed-b082-b414dbef47fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m103"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
